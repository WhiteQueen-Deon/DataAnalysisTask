{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f7397684",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "be53b66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_price(price_str):\n",
    "\n",
    "    if pd.isna(price_str):\n",
    "        return None\n",
    "\n",
    "    price_str = str(price_str).strip()\n",
    "    is_euro = ('â‚¬' in price_str) or ('EUR' in price_str.upper())\n",
    "\n",
    "    price_str = price_str.replace('$', '').replace('â‚¬', '').replace('USD', '').replace('EUR', '').replace('Â¢', '.').strip()\n",
    "    \n",
    "    try:\n",
    "        price = float(price_str)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "    if is_euro:\n",
    "        price = price * 1.2\n",
    "\n",
    "    return price\n",
    "\n",
    "\n",
    "def clean_timestamp(timestamp_str):\n",
    "\n",
    "    if pd.isna(timestamp_str):\n",
    "        return None\n",
    "    \n",
    "    timestamp_str = str(timestamp_str).strip()\n",
    "    timestamp_str = timestamp_str.replace(';', ' ').replace(',', ' ')\n",
    "    timestamp_str = timestamp_str.replace('A.M.', 'AM').replace('P.M.', 'PM')\n",
    "    \n",
    "    iso_pattern = r'\\d{4}-\\d{2}-\\d{2}'\n",
    "    if re.search(iso_pattern, timestamp_str):\n",
    "        result = pd.to_datetime(timestamp_str, errors='coerce', dayfirst=False)\n",
    "    else:\n",
    "        result = pd.to_datetime(timestamp_str, errors='coerce', dayfirst=True)\n",
    "    \n",
    "    return result\n",
    "\n",
    "class UnionFind:\n",
    "    def __init__(self, n):\n",
    "        self.parent = list(range(n))  \n",
    "    \n",
    "    def find(self, x):\n",
    "        if self.parent[x] != x:\n",
    "            self.parent[x] = self.find(self.parent[x])  \n",
    "        return self.parent[x]\n",
    "    \n",
    "    def union(self, x, y):\n",
    "        root_x = self.find(x)\n",
    "        root_y = self.find(y)\n",
    "        if root_x != root_y:\n",
    "            self.parent[root_x] = root_y\n",
    "    \n",
    "    def count_groups(self):\n",
    "        return len(set(self.find(i) for i in range(len(self.parent))))\n",
    "    \n",
    "    def get_group_members(self, x):\n",
    "        root = self.find(x)\n",
    "        return [i for i in range(len(self.parent)) if self.find(i) == root]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "83c465c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analyze_dataset function defined\n"
     ]
    }
   ],
   "source": [
    "def analyze_dataset(dataset_name):\n",
    "    \n",
    "    print(f\"ANALYZING: {dataset_name}\")\n",
    "    \n",
    "    # ===== 1. LOAD DATA =====\n",
    "    orders_df = pd.read_parquet(f'{dataset_name}/orders.parquet', engine='fastparquet')\n",
    "    users_df = pd.read_csv(f'{dataset_name}/users.csv')\n",
    "    \n",
    "    with open(f'{dataset_name}/books.yaml', 'r', encoding='utf-8') as file:\n",
    "        books_data = yaml.safe_load(file)\n",
    "    books_df = pd.DataFrame(books_data)\n",
    "    books_df.columns = books_df.columns.str.replace(':', '')\n",
    "    \n",
    "    print(f\"   Loaded {len(orders_df):,} orders\")\n",
    "    print(f\"   Loaded {len(users_df):,} users\")\n",
    "    print(f\"   Loaded {len(books_df):,} books\\n\")\n",
    "    \n",
    "    # ===== 2. CLEAN ORDERS =====\n",
    "    print(\"ðŸ§¹ Cleaning orders data...\")\n",
    "    orders_df['clean_price'] = orders_df['unit_price'].apply(clean_price)\n",
    "    orders_df['clean_timestamp'] = orders_df['timestamp'].apply(clean_timestamp)\n",
    "    \n",
    "    before_clean = len(orders_df)\n",
    "    orders_df = orders_df.dropna(subset=['clean_price', 'clean_timestamp'])\n",
    "    after_clean = len(orders_df)\n",
    "    \n",
    "    orders_df['paid_price'] = orders_df['quantity'] * orders_df['clean_price']\n",
    "    orders_df['date'] = orders_df['clean_timestamp'].dt.date\n",
    "    orders_df = orders_df.drop_duplicates(subset=['id'])\n",
    "    \n",
    "    print(f\"   Removed {before_clean - after_clean:,} invalid rows\")\n",
    "    print(f\"   Final orders count: {len(orders_df):,}\\n\")\n",
    "    \n",
    "    # ===== 3. BUILD UNION-FIND FOR USERS =====\n",
    "    print(\"Building user deduplication structure...\")\n",
    "    n_users = len(users_df)\n",
    "    uf = UnionFind(n_users)\n",
    "    users_clean = users_df.copy()\n",
    "    \n",
    "    # Fill missing addresses\n",
    "    na_mask = users_clean['address'].isna()\n",
    "    na_count = na_mask.sum()\n",
    "    users_clean.loc[na_mask, 'address'] = [f'MISSING_ADDRESS_{i}' for i in range(na_count)]\n",
    "    \n",
    "    # Union users with matching fields\n",
    "    for field in ['email', 'phone', 'name', 'address']:\n",
    "        groups = users_clean.groupby(field).groups\n",
    "        for indices in groups.values():\n",
    "            if len(indices) > 1:\n",
    "                first = indices[0]\n",
    "                for idx in indices[1:]:\n",
    "                    uf.union(first, idx)\n",
    "    \n",
    "    print(f\"  User deduplication complete\\n\")\n",
    "    \n",
    "    # ===== EXECUTE 6 TASKS =====\n",
    "    results = {}\n",
    "    \n",
    "    # --- TASK 1: Top 5 Revenue Days ---\n",
    "    print(\"Task 1: Top 5 Revenue Days\")\n",
    "    top5_days = orders_df.groupby('date')['paid_price'].sum().sort_values(ascending=False).head(5)\n",
    "    results['task1'] = top5_days\n",
    "    for i, (date, revenue) in enumerate(top5_days.items(), 1):\n",
    "        print(f\"   {i}. {date}: ${revenue:,.2f}\")\n",
    "    print()\n",
    "    \n",
    "    # --- TASK 2: Unique Users ---\n",
    "    print(\"Task 2: Real Unique Users\")\n",
    "    unique_users = uf.count_groups()\n",
    "    results['task2'] = unique_users\n",
    "    print(f\"   Total records: {len(users_df):,}\")\n",
    "    print(f\"   Real unique users: {unique_users:,}\")\n",
    "    print(f\"   Duplicates found: {len(users_df) - unique_users:,}\\n\")\n",
    "    \n",
    "    # --- TASK 3: Author Sets ---\n",
    "    print(\"Task 3: Unique Author Sets\")\n",
    "    author_sets = set()\n",
    "    for author_str in books_df['author']:\n",
    "        if pd.isna(author_str):\n",
    "            continue\n",
    "        authors = [a.strip() for a in str(author_str).split(',')]\n",
    "        author_tuple = tuple(sorted(authors))\n",
    "        author_sets.add(author_tuple)\n",
    "    results['task3'] = len(author_sets)\n",
    "    print(f\"   Unique author sets: {len(author_sets):,}\\n\")\n",
    "    \n",
    "    # --- TASK 4: Most Popular Author ---\n",
    "    print(\"Task 4: Most Popular Author\")\n",
    "    book_sales = orders_df.groupby('book_id')['quantity'].sum()\n",
    "    books_with_sales = books_df.merge(book_sales, left_on='id', right_index=True, how='left')\n",
    "    books_with_sales['quantity'] = books_with_sales['quantity'].fillna(0)\n",
    "    \n",
    "    def standardize_author(author_str):\n",
    "        if pd.isna(author_str):\n",
    "            return ()\n",
    "        authors = [a.strip() for a in str(author_str).split(',')]\n",
    "        return tuple(sorted(authors))\n",
    "    \n",
    "    books_with_sales['author_set'] = books_with_sales['author'].apply(standardize_author)\n",
    "    author_sales = books_with_sales.groupby('author_set')['quantity'].sum().sort_values(ascending=False)\n",
    "    \n",
    "    most_popular = author_sales.idxmax()\n",
    "    max_sales = author_sales.max()\n",
    "    results['task4'] = {'authors': most_popular, 'books_sold': int(max_sales)}\n",
    "    \n",
    "    author_name = most_popular[0] if len(most_popular) == 1 else ' & '.join(most_popular)\n",
    "    print(f\"   Most popular: {author_name}\")\n",
    "    print(f\"   Books sold: {int(max_sales):,}\\n\")\n",
    "    \n",
    "    # --- TASK 5: Top Customer ---\n",
    "    print(\"Task 5: Top Customer\")\n",
    "    user_spending = orders_df.groupby('user_id')['paid_price'].sum()\n",
    "    real_user_spending = {}\n",
    "    \n",
    "    for user_id, spending in user_spending.items():\n",
    "        user_rows = users_clean[users_clean['id'] == user_id]\n",
    "        if len(user_rows) == 0:\n",
    "            continue\n",
    "        user_idx = user_rows.index[0]\n",
    "        root = uf.find(user_idx)\n",
    "        if root not in real_user_spending:\n",
    "            real_user_spending[root] = 0\n",
    "        real_user_spending[root] += spending\n",
    "    \n",
    "    top_real_user = max(real_user_spending, key=real_user_spending.get)\n",
    "    max_spending = real_user_spending[top_real_user]\n",
    "    all_user_indices = uf.get_group_members(top_real_user)\n",
    "    all_user_ids = users_clean.loc[all_user_indices, 'id'].tolist()\n",
    "    \n",
    "    results['task5'] = {'user_ids': all_user_ids, 'total_spending': max_spending}\n",
    "    print(f\"   Total spending: ${max_spending:,.2f}\")\n",
    "    print(f\"   User IDs: {all_user_ids}\")\n",
    "    print(f\"   Number of aliases: {len(all_user_ids)}\\n\")\n",
    "    \n",
    "    # --- TASK 6: Daily Revenue Chart ---\n",
    "    print(\"Task 6: Daily Revenue Chart\")\n",
    "    daily_revenue = orders_df.groupby('date')['paid_price'].sum().sort_index()\n",
    "    \n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.plot(daily_revenue.index, daily_revenue.values, \n",
    "             marker='o', linestyle='-', linewidth=2, markersize=4, color='#2E86AB')\n",
    "    plt.fill_between(daily_revenue.index, daily_revenue.values, alpha=0.2, color='#2E86AB')\n",
    "    \n",
    "    plt.title(f'Daily Revenue Over Time - {dataset_name}', fontsize=16, fontweight='bold')\n",
    "    plt.xlabel('Date', fontsize=12)\n",
    "    plt.ylabel('Revenue ($)', fontsize=12)\n",
    "    plt.grid(True, alpha=0.3, linestyle='--')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    chart_filename = f'daily_revenue_{dataset_name}.png'\n",
    "    plt.savefig(chart_filename, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    results['task6'] = chart_filename\n",
    "    print(f\"   âœ“ Chart saved: {chart_filename}\\n\")\n",
    "    \n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"{dataset_name} ANALYSIS COMPLETE\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"analyze_dataset function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fda6094",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
